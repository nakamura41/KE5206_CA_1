{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e05535dd-21d5-4b69-9c52-0eec04aec10a",
    "_uuid": "bde6f13675f847c579ea8d6481e1f34ba62a8741"
   },
   "source": [
    "# Predicting hart disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8e33d119-031c-4c2c-b515-abeb55c93d33",
    "_uuid": "c72059f9b5a2921746f0d4572493a86b8a80f13d"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Relevance. According to a report of the American Heart Association Statistics (2016), heart disease is the leading cause of death for both men and women and responsible for 1 in every 4 deaths, even modest improvements in prognostic models of heart event and complications could save literally hundreds of lives and help to significantly reduce the cost of health care services, medications, and lost productivity.\n",
    "\n",
    "\n",
    "file:///C:/Users/User/Downloads/350-904-1-PB%20(1).pdf\n",
    "http://inpressco.com/wp-content/uploads/2017/10/Paper271842-1853.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d9e16edc-196c-484e-81b4-4eedb6ca272b",
    "_uuid": "986a1b696e4150bf75309c776ee7bbf10b8a46d0"
   },
   "source": [
    "## Methods \n",
    "\n",
    "Deep neural networks (DNN) represents a set of modern machine learning (ML) models that have gain widespread recognition because they were behind the first FDA (US food and drug administration) approved machine learning application in healthcare; to be approved it had to pass tests to show it can produce results at least as accurately as humans are currently able to. Recently, such ML models were also used to detect with cardiologist-level accuracy 14 types of arrhythmias (sometime life-threatening heart beats) form ECG-electrocardiogram signals generated by wearable monitors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "765b1f2f-5b6c-4b3e-a1f6-66d61a8c9aea",
    "_uuid": "22795be3a63f7e30c2c2d2a2fc20ced2eac392e9"
   },
   "source": [
    "## Original contribution\n",
    "\n",
    "Studies exploring the potential of this technology for the prognosis of cardiovascular events/complications from risk factors have been limited; events/complications are, for example, coronary artery disease, stroke and congestive heart failure, and risk factors are those established by the American College of Cardiology/American Heart Association (ACC/AHA) such as age, high blood pressure, high LDL cholesterol, and smoking and others, such as, systolic blood pressure variability, kidney disease, and ethnicity. \n",
    "\n",
    "Most of previous studies have either used logistic regression or classical machine learning algorithms such as random forest, gradient boosting and neural networks (non-deep); in addition, comparison studies of the cited algorithms with deep learning models in the specific prognosis context under consideration are not readily available. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fb0e279a-85db-4ff4-9e19-d0afd7678579",
    "_uuid": "425fc124a20f4d6392ee1840a9df54c84844e81b"
   },
   "source": [
    "## Research objectives\n",
    "\n",
    "Establish the relative performance of deep learning models, such as deep belief networks and convolutional neural networks, and ensembles with respect to classical machine learning algorithms (including logistic regression) using cases studies built from well-known heart disease data sets such as the Cleveland set available from the UCI repository. Research questions of interest are, for example, for what would be the threshold of sample size in heart disease studies where the more complex but potentially more effective deep learning models would be recommended?, would ensembles of machine learning models be able to provide more robust predictions as it has been the case in other knowledge domains?, does the ACC/AHA list of eight risk factors should be updated with other genetic or lifestyle factors?. The deep learning models will be implemented in Tensorflow (originally from Google, now open source) and healthcare.ai, an open source that facilitate the development of machine learning in healthcare, with the prevision that can handle so called big data by using the Hadoop/Spark platform.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "_cell_guid": "8e8b8c1f-ad72-40d7-9508-81e528bd46bb",
    "_uuid": "7c1d8044361a7931707cddb7492fd68e48016b44",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "\n",
    "from imblearn.over_sampling import SMOTE #for SMOTE -> install package using: conda install -c conda-forge imbalanced-learn \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "_cell_guid": "235d000d-7d9a-4dc9-a5e9-a8a475b9896f",
    "_uuid": "8a0522ef39bfa8d1a18cd75f8202e583661d759b"
   },
   "outputs": [],
   "source": [
    "from scipy import stats, integrate\n",
    "import matplotlib.pyplot as plt\n",
    "import ggplot\n",
    "import scipy\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.decomposition import PCA\n",
    "import pylab as pl\n",
    "from itertools import cycle\n",
    "from sklearn import cross_validation\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "_cell_guid": "4e8a77fd-b674-46fb-b480-ad6c0b3a5d7f",
    "_uuid": "d12c643fdd7a7479fdc3d5d6e65567e11a34203d",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                 int64\n",
       "sex                 int64\n",
       "cp                  int64\n",
       "trestbps            int64\n",
       "chol                int64\n",
       "fbs                 int64\n",
       "restecg             int64\n",
       "thalach             int64\n",
       "exang               int64\n",
       "oldpeak           float64\n",
       "slop                int64\n",
       "ca                 object\n",
       "thal               object\n",
       "pred_attribute      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_list = ['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','class']\n",
    "dataset1=pd.read_csv(\"Heart_Disease_Data.csv\")\n",
    "dataset2=pd.read_csv(\"Heart_Disease_Data.csv\")\n",
    "dataset1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: FutureWarning: convert_objects is deprecated.  Use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "age                float64\n",
       "sex               category\n",
       "cp                category\n",
       "trestbps           float64\n",
       "chol               float64\n",
       "fbs                float64\n",
       "restecg           category\n",
       "thalach            float64\n",
       "exang             category\n",
       "oldpeak            float64\n",
       "slop              category\n",
       "ca                 float64\n",
       "thal              category\n",
       "pred_attribute     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you already have numeric dtypes (int8|16|32|64,float64,boolean) you can convert it to another \"numeric\" dtype using Pandas .astype() method. Demo: In [90]: df = pd.DataFrame(np.random.randint(10**5,10**7,(5,3)),columns=list('abc'), dtype=np.int64) In [91]: df Out[91]: a b c 0 9059440 9590567 2076918 1 5861102 4566089 1947323 2 6636568 162770 2487991 3 6794572 5236903 5628779 4 470121 4044395 4546794 In [92]: df.dtypes Out[92]: a int64 b int64 c int64 dtype: object In [93]: df['a'] = df['a'].astype(float) In [94]: df.dtypes Out[94]: a float64 b int64 c int64 dtype: object It won't work for object (string) dtypes, that can't be converted to numbers: In [95]: df.loc[1, 'b'] = 'XXXXXX' In [96]: df Out[96]:...\n",
    "# Just make everything numeric for ease\n",
    "dataset1 = dataset1.convert_objects(convert_numeric=True)\n",
    "dataset1 = dataset1.astype('float')\n",
    "# 1. age: continuous\n",
    "# 2. sex: categorical, 2 values {0: female, 1: male}\n",
    "#  3. cp (chest pain type): categorical, 4 values\n",
    "#     {1: typical angina, 2: atypical angina, 3: non-angina, 4: asymptomatic angina}\n",
    "#  4. restbp (resting blood pressure on admission to hospital): continuous (mmHg)\n",
    "#  5. chol (serum cholesterol level): continuous (mg/dl)\n",
    "#  6. fbs (fasting blood sugar): categorical, 2 values {0: <= 120 mg/dl, 1: > 120 mg/dl}\n",
    "#  7. restecg (resting electrocardiography): categorical, 3 values\n",
    "#     {0: normal, 1: ST-T wave abnormality, 2: left ventricular hypertrophy}\n",
    "#  8. thalach (maximum heart rate achieved): continuous\n",
    "#  9. exang (exercise induced angina): categorical, 2 values {0: no, 1: yes}\n",
    "# 10. oldpeak (ST depression induced by exercise relative to rest): continuous\n",
    "# 11. slope (slope of peak exercise ST segment): categorical, 3 values \n",
    "#     {1: upsloping, 2: flat, 3: downsloping}\n",
    "# 12. ca (number of major vessels colored by fluoroscopy): discrete (0,1,2,3)\n",
    "# 13. thal: categorical, 3 values {3: normal, 6: fixed defect, 7: reversible defect}\n",
    "# 14. num (diagnosis of heart disease): categorical, 5 values \n",
    "#     {0: less than 50% narrowing in any major vessel, \n",
    "#     1-4: more than 50% narrowing in 1-4 vessels}\n",
    "# number of vessels which are narrowing --> don't think this is categorical!\n",
    "\n",
    "# dataset[['col2','col3']] = df[['col2','col3']].apply(pd.to_category)\n",
    "\n",
    "dataset1[\"sex\"] = dataset1[\"sex\"].astype('category')\n",
    "dataset1[\"cp\"] = dataset1[\"cp\"].astype('category')\n",
    "dataset1[\"restecg\"] = dataset1[\"restecg\"].astype('category')\n",
    "dataset1[\"exang\"] = dataset1[\"exang\"].astype('category')\n",
    "dataset1[\"slop\"] = dataset1[\"slop\"].astype('category')\n",
    "dataset1[\"thal\"] = dataset1[\"thal\"].astype('category')\n",
    "# dataset1['fbs'] = dataset1['fbs'].astype('category')\n",
    "dataset1.dtypes\n",
    "# SVM requires that each data instance is represented as a vector of real numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               False\n",
       "sex               False\n",
       "cp                False\n",
       "trestbps          False\n",
       "chol              False\n",
       "fbs               False\n",
       "restecg           False\n",
       "thalach           False\n",
       "exang             False\n",
       "oldpeak           False\n",
       "slop              False\n",
       "ca                 True\n",
       "thal               True\n",
       "pred_attribute    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### count missing value in terms of colunms #######\n",
    "#dataset.shape[0] - dataset.count()\n",
    "dataset1.isnull()\n",
    "dataset1.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1.duplicated().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing values and/or any duplicated data in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outlier:  34.0\n",
      "outlier:  29.0\n",
      "outlier:  77.0\n",
      "outlier:  34.0\n",
      "outlier:  76.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  172.0\n",
      "outlier:  170.0\n",
      "outlier:  180.0\n",
      "outlier:  200.0\n",
      "outlier:  94.0\n",
      "outlier:  170.0\n",
      "outlier:  165.0\n",
      "outlier:  174.0\n",
      "outlier:  178.0\n",
      "outlier:  192.0\n",
      "outlier:  180.0\n",
      "outlier:  178.0\n",
      "outlier:  94.0\n",
      "outlier:  180.0\n",
      "outlier:  170.0\n",
      "outlier:  170.0\n",
      "outlier:  164.0\n",
      "outlier:  354.0\n",
      "outlier:  340.0\n",
      "outlier:  353.0\n",
      "outlier:  417.0\n",
      "outlier:  360.0\n",
      "outlier:  141.0\n",
      "outlier:  341.0\n",
      "outlier:  407.0\n",
      "outlier:  564.0\n",
      "outlier:  394.0\n",
      "outlier:  409.0\n",
      "outlier:  126.0\n",
      "outlier:  342.0\n",
      "outlier:  131.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  1.0\n",
      "outlier:  99.0\n",
      "outlier:  97.0\n",
      "outlier:  202.0\n",
      "outlier:  96.0\n",
      "outlier:  88.0\n",
      "outlier:  95.0\n",
      "outlier:  96.0\n",
      "outlier:  71.0\n",
      "outlier:  90.0\n",
      "outlier:  3.5\n",
      "outlier:  3.6\n",
      "outlier:  3.4\n",
      "outlier:  3.6\n",
      "outlier:  6.2\n",
      "outlier:  3.6\n",
      "outlier:  4.0\n",
      "outlier:  5.6\n",
      "outlier:  4.0\n",
      "outlier:  4.2\n",
      "outlier:  4.2\n",
      "outlier:  3.8\n",
      "outlier:  3.4\n",
      "outlier:  3.6\n",
      "outlier:  4.4\n",
      "outlier:  4.0\n",
      "outlier:  3.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:4269: RuntimeWarning: Invalid value encountered in percentile\n",
      "  interpolation=interpolation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130, 'outliers. That is', 43.0, 'percent of the total list')\n"
     ]
    }
   ],
   "source": [
    "def checkforoutlier(df):\n",
    "    outliersnumbers = 0\n",
    "    for column in df:\n",
    "        for number in df[column]:\n",
    "            if number < np.percentile(\n",
    "                df[column], 25)-(np.percentile(\n",
    "                df[column], 75)-np.percentile(\n",
    "                df[column], 25)) or number > np.percentile(\n",
    "                df[column], 75)+(np.percentile(\n",
    "                df[column], 75)-np.percentile(\n",
    "                df[column], 25)):\n",
    "                    print(\"outlier: \", number)\n",
    "                    outliersnumbers += 1\n",
    "    return outliersnumbers, 'outliers. That is', round(float(outliersnumbers)/float(len(df[column]))*100, 0), 'percent of the total list'\n",
    "\n",
    "print(checkforoutlier(dataset1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset1 = dataset1.fillna(value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preliminary description of the data.\n",
    "Box plots and histograms were used for continuous and categorical variables.\n",
    "Basic statistics are also available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3f859aa0-fc03-4325-9378-48012735d14b",
    "_uuid": "9b92fe125729a3cfafb6752fdef27f84d982ddcf",
    "collapsed": true
   },
   "source": [
    "# Continuous variables \n",
    "basic statistics + Box plots + histograms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "_cell_guid": "4d835113-542b-41ad-9654-6b59ddd99954",
    "_uuid": "de5b369e4cdeb022b60051ee868a5539d9c01429",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>thalach</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>ca</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>299.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.438944</td>\n",
       "      <td>131.689769</td>\n",
       "      <td>246.693069</td>\n",
       "      <td>149.607261</td>\n",
       "      <td>1.039604</td>\n",
       "      <td>0.672241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.038662</td>\n",
       "      <td>17.599748</td>\n",
       "      <td>51.776918</td>\n",
       "      <td>22.875003</td>\n",
       "      <td>1.161075</td>\n",
       "      <td>0.937438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>275.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age    trestbps        chol     thalach     oldpeak          ca\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  299.000000\n",
       "mean    54.438944  131.689769  246.693069  149.607261    1.039604    0.672241\n",
       "std      9.038662   17.599748   51.776918   22.875003    1.161075    0.937438\n",
       "min     29.000000   94.000000  126.000000   71.000000    0.000000    0.000000\n",
       "25%     48.000000  120.000000  211.000000  133.500000    0.000000    0.000000\n",
       "50%     56.000000  130.000000  241.000000  153.000000    0.800000    0.000000\n",
       "75%     61.000000  140.000000  275.000000  166.000000    1.600000    1.000000\n",
       "max     77.000000  200.000000  564.000000  202.000000    6.200000    3.000000"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## basic statistic descriptions\n",
    "continuas=[\"age\", \"trestbps\", \"chol\", \"thalach\", \"oldpeak\", \"ca\"]\n",
    "dataset1[continuas].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d0086eee10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## age histogram\n",
    "ag= np.array(dataset1['age']) \n",
    "plt.hist(ag, bins = 6) \n",
    "plt.title(\"age\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXpIaZ9BLUuP+HyUCD50MzelaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d00a25a1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## trestbps histogram\n",
    "tp= np.array(dataset1['trestbps']) \n",
    "plt.hist(tp, bins=6) \n",
    "plt.title(\"Trestbps:blood pressure\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d00a272e48>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## chol histogram\n",
    "ch= np.array(dataset1['chol'])\n",
    "sns.distplot(ch, rug=True, hist=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d00a272e48>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## thalach histogram and distribution \n",
    "tl= np.array(dataset1['thalach'])\n",
    "sns.distplot(tl, rug=True, hist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d00a272e48>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## oldpeak histogram and distribution \n",
    "op= np.array(dataset1['oldpeak'])\n",
    "sns.distplot(op, rug=True, hist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEICAYAAABfz4NwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d00a25a8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## thalach histogram\n",
    "ca= np.array(dataset1['ca']) \n",
    "plt.hist(tp, bins=4) \n",
    "plt.title(\"histogram of ca\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "992069e9-2599-4b46-84a2-6c5e8abc9e08",
    "_uuid": "25d656add052b4b9c70dc409b1103ada4fe1a9db",
    "collapsed": true
   },
   "source": [
    "### Categorical variables \n",
    "##### Histograms + basic statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d00a3cdf98>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sex: sex (1 = male; 0 = female) \n",
    "tempo5 = dataset1['sex']\n",
    "tempo5.value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "_cell_guid": "165acbd9-e9f2-49cc-a163-a1a714b231b2",
    "_uuid": "b2ca56f6aa50c9cbe163fda300dc05dc77be5f95"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d00a3cdf98>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fbs: (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n",
    "tempo6 = dataset1['fbs']\n",
    "tempo6.value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "_cell_guid": "94cb7d70-07ea-4dc8-a686-34e40e3a88dc",
    "_uuid": "6f86e31d259f4c6982fbf5d8761edab341602669"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d00a3cdf98>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Slope: the slope of the peak exercise ST segment  \n",
    "#Value 1: upsloping \n",
    "#Value 2: flat \n",
    "#Value 3: downsloping\n",
    "tempo7 = dataset1['slop']\n",
    "tempo7.value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "_cell_guid": "6a689218-4173-4169-90e6-ba2640dde924",
    "_uuid": "d7e4dceb43a2a6c598aab5b796a8f64fabb3a0e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d00a3cdf98>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cp: chest pain type\n",
    "#Value 1: typical angina \n",
    "#Value 2: atypical angina \n",
    "#Value 3: non-anginal pain \n",
    "#Value 4: asymptomatic \n",
    "tempo8 = dataset1['cp']\n",
    "tempo8.value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "_cell_guid": "66a9c02d-11b8-41a8-a97e-bca3c7278939",
    "_uuid": "dee8d81e3efe783c3a2dc6fea7432fa2a2bd0a95"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d00a3cdf98>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exang: exercise induced angina (1 = yes; 0 = no) \n",
    "tempo9 = dataset1['exang']\n",
    "tempo9.value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "_cell_guid": "235ab7fb-3a08-4c8e-bd2c-4ef8e6d1129e",
    "_uuid": "ad4719dc5cf0476037d683dee63f728d0fec4ed8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d00a3cdf98>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Thal: 3 = normal; 6 = fixed defect; 7 = reversable defect \n",
    "tempo10 = dataset1['thal']\n",
    "tempo10.value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "_cell_guid": "a1ab9dce-1b82-4556-8dee-6a6f50303389",
    "_uuid": "cbc6ce5594ddb4b57821ddff0770176499a24c17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d00a3cdf98>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Restecg: resting electrocardiographic results \n",
    "#Value 0: normal \n",
    "#Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV) \n",
    "#Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria \n",
    "tempo11 = dataset1['restecg']\n",
    "tempo11.value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "_cell_guid": "7140b7fd-b218-4ba8-b78a-b2282104c6d5",
    "_uuid": "7d82c9ede07d463dc884534cafbed825b948a975"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d00a3cdf98>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Class: diagnosis of heart disease (angiographic disease status) \n",
    "#Value 0: < 50% diameter narrowing (Healthy)\n",
    "#Value 1: > 50% diameter narrowing (Sick)\n",
    "tempo12 = dataset1['pred_attribute']\n",
    "tempo12.value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ggplot import *\n",
    "# p = ggplot(dataset1,aes(x='pred_attribute'))\n",
    "# p + geom_bar()+facet_wrap('sex')  #### relationship between pred_attribute and sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### relationship between age and trestbps\n",
    "# p = ggplot(dataset1,aes(x='age'))\n",
    "# p+geom_histogram()+facet_wrap('pred_attribute')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p=ggplot(dataset1,aes(x='age',y='trestbps'))\n",
    "# p+geom_line()+facet_wrap('pred_attribute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p=ggplot(dataset1,aes(x='age',y='thalach'))\n",
    "# p+geom_line()+facet_wrap('pred_attribute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = ggplot(dataset1,aes(x='pred_attribute'))\n",
    "# p + geom_bar()+facet_wrap('cp') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# p = ggplot(dataset1,aes(x='pred_attribute'))\n",
    "# p + geom_bar()+facet_wrap('fbs') \n",
    "# ggplot(data)+geom_histogram(aes(x=price, fill=cut), position=\"dodge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data processing\n",
    " outlier and balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ## Boxplots of all continuous variable\n",
    "# continuas=[\"age\", \"trestbps\", \"chol\", \"thalach\", \"oldpeak\", \"ca\"]\n",
    "# dataset[continuas].boxplot(return_type='axes', figsize=(12,8))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ### show the patients whose trestbps above 180\n",
    "# print(dataset[dataset['trestbps']>=180])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ### show the patients whose chol above 370\n",
    "# print(dataset[dataset['chol']>400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ### show the patients whose thalach below 180\n",
    "# print(dataset[dataset['thalach']<90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ### show the patients whose thalach below 180\n",
    "# print(dataset[dataset['oldpeak']>5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #### delete outliers by mean\n",
    "# dataset1=dataset1.drop([83,126,188,201,231,48,121,152,181,175,245,91,123])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#import numpy as np\n",
    "#from sklearn.cluster import KMeans\n",
    "#data=dataset1\n",
    "#estimator = KMeans(n_clusters=3)\n",
    "#estimator.fit(data)#聚类\n",
    "#label_pred = estimator.labels_ #获取聚类标签\n",
    "#centroids = estimator.cluster_centers_ \n",
    "#inertia = estimator.inertia_ \n",
    "#mark = ['or', 'ob', 'og', 'ok', '^r', '+r', 'sr', 'dr'] \n",
    "#color = 0\n",
    "#j = 0 \n",
    "#for i in label_pred:\n",
    "    #plt.plot([data[j:j+1,0]], [data[j:j+1,1]], mark[i], markersize = 5)\n",
    "    #j +=1\n",
    "#plt.show()''''''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# correlation between variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slop</th>\n",
       "      <th>pred_attribute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.097542</td>\n",
       "      <td>0.104139</td>\n",
       "      <td>0.284946</td>\n",
       "      <td>0.208950</td>\n",
       "      <td>0.118530</td>\n",
       "      <td>0.148868</td>\n",
       "      <td>-0.393806</td>\n",
       "      <td>0.091661</td>\n",
       "      <td>0.203805</td>\n",
       "      <td>0.161770</td>\n",
       "      <td>0.222853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>-0.097542</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010084</td>\n",
       "      <td>-0.064456</td>\n",
       "      <td>-0.199915</td>\n",
       "      <td>0.047862</td>\n",
       "      <td>0.021647</td>\n",
       "      <td>-0.048663</td>\n",
       "      <td>0.146201</td>\n",
       "      <td>0.102173</td>\n",
       "      <td>0.037533</td>\n",
       "      <td>0.224469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp</th>\n",
       "      <td>0.104139</td>\n",
       "      <td>0.010084</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.036077</td>\n",
       "      <td>0.072319</td>\n",
       "      <td>-0.039975</td>\n",
       "      <td>0.067505</td>\n",
       "      <td>-0.334422</td>\n",
       "      <td>0.384060</td>\n",
       "      <td>0.202277</td>\n",
       "      <td>0.152050</td>\n",
       "      <td>0.407075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trestbps</th>\n",
       "      <td>0.284946</td>\n",
       "      <td>-0.064456</td>\n",
       "      <td>-0.036077</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.130120</td>\n",
       "      <td>0.175340</td>\n",
       "      <td>0.146560</td>\n",
       "      <td>-0.045351</td>\n",
       "      <td>0.064762</td>\n",
       "      <td>0.189171</td>\n",
       "      <td>0.117382</td>\n",
       "      <td>0.157754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chol</th>\n",
       "      <td>0.208950</td>\n",
       "      <td>-0.199915</td>\n",
       "      <td>0.072319</td>\n",
       "      <td>0.130120</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009841</td>\n",
       "      <td>0.171043</td>\n",
       "      <td>-0.003432</td>\n",
       "      <td>0.061310</td>\n",
       "      <td>0.046564</td>\n",
       "      <td>-0.004062</td>\n",
       "      <td>0.070909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fbs</th>\n",
       "      <td>0.118530</td>\n",
       "      <td>0.047862</td>\n",
       "      <td>-0.039975</td>\n",
       "      <td>0.175340</td>\n",
       "      <td>0.009841</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069564</td>\n",
       "      <td>-0.007854</td>\n",
       "      <td>0.025665</td>\n",
       "      <td>0.005747</td>\n",
       "      <td>0.059894</td>\n",
       "      <td>0.059186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restecg</th>\n",
       "      <td>0.148868</td>\n",
       "      <td>0.021647</td>\n",
       "      <td>0.067505</td>\n",
       "      <td>0.146560</td>\n",
       "      <td>0.171043</td>\n",
       "      <td>0.069564</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.083389</td>\n",
       "      <td>0.084867</td>\n",
       "      <td>0.114133</td>\n",
       "      <td>0.133946</td>\n",
       "      <td>0.183696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thalach</th>\n",
       "      <td>-0.393806</td>\n",
       "      <td>-0.048663</td>\n",
       "      <td>-0.334422</td>\n",
       "      <td>-0.045351</td>\n",
       "      <td>-0.003432</td>\n",
       "      <td>-0.007854</td>\n",
       "      <td>-0.083389</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.378103</td>\n",
       "      <td>-0.343085</td>\n",
       "      <td>-0.385601</td>\n",
       "      <td>-0.415040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exang</th>\n",
       "      <td>0.091661</td>\n",
       "      <td>0.146201</td>\n",
       "      <td>0.384060</td>\n",
       "      <td>0.064762</td>\n",
       "      <td>0.061310</td>\n",
       "      <td>0.025665</td>\n",
       "      <td>0.084867</td>\n",
       "      <td>-0.378103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.288223</td>\n",
       "      <td>0.257748</td>\n",
       "      <td>0.397057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oldpeak</th>\n",
       "      <td>0.203805</td>\n",
       "      <td>0.102173</td>\n",
       "      <td>0.202277</td>\n",
       "      <td>0.189171</td>\n",
       "      <td>0.046564</td>\n",
       "      <td>0.005747</td>\n",
       "      <td>0.114133</td>\n",
       "      <td>-0.343085</td>\n",
       "      <td>0.288223</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.577537</td>\n",
       "      <td>0.504092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slop</th>\n",
       "      <td>0.161770</td>\n",
       "      <td>0.037533</td>\n",
       "      <td>0.152050</td>\n",
       "      <td>0.117382</td>\n",
       "      <td>-0.004062</td>\n",
       "      <td>0.059894</td>\n",
       "      <td>0.133946</td>\n",
       "      <td>-0.385601</td>\n",
       "      <td>0.257748</td>\n",
       "      <td>0.577537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.377957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_attribute</th>\n",
       "      <td>0.222853</td>\n",
       "      <td>0.224469</td>\n",
       "      <td>0.407075</td>\n",
       "      <td>0.157754</td>\n",
       "      <td>0.070909</td>\n",
       "      <td>0.059186</td>\n",
       "      <td>0.183696</td>\n",
       "      <td>-0.415040</td>\n",
       "      <td>0.397057</td>\n",
       "      <td>0.504092</td>\n",
       "      <td>0.377957</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     age       sex        cp  trestbps      chol       fbs  \\\n",
       "age             1.000000 -0.097542  0.104139  0.284946  0.208950  0.118530   \n",
       "sex            -0.097542  1.000000  0.010084 -0.064456 -0.199915  0.047862   \n",
       "cp              0.104139  0.010084  1.000000 -0.036077  0.072319 -0.039975   \n",
       "trestbps        0.284946 -0.064456 -0.036077  1.000000  0.130120  0.175340   \n",
       "chol            0.208950 -0.199915  0.072319  0.130120  1.000000  0.009841   \n",
       "fbs             0.118530  0.047862 -0.039975  0.175340  0.009841  1.000000   \n",
       "restecg         0.148868  0.021647  0.067505  0.146560  0.171043  0.069564   \n",
       "thalach        -0.393806 -0.048663 -0.334422 -0.045351 -0.003432 -0.007854   \n",
       "exang           0.091661  0.146201  0.384060  0.064762  0.061310  0.025665   \n",
       "oldpeak         0.203805  0.102173  0.202277  0.189171  0.046564  0.005747   \n",
       "slop            0.161770  0.037533  0.152050  0.117382 -0.004062  0.059894   \n",
       "pred_attribute  0.222853  0.224469  0.407075  0.157754  0.070909  0.059186   \n",
       "\n",
       "                 restecg   thalach     exang   oldpeak      slop  \\\n",
       "age             0.148868 -0.393806  0.091661  0.203805  0.161770   \n",
       "sex             0.021647 -0.048663  0.146201  0.102173  0.037533   \n",
       "cp              0.067505 -0.334422  0.384060  0.202277  0.152050   \n",
       "trestbps        0.146560 -0.045351  0.064762  0.189171  0.117382   \n",
       "chol            0.171043 -0.003432  0.061310  0.046564 -0.004062   \n",
       "fbs             0.069564 -0.007854  0.025665  0.005747  0.059894   \n",
       "restecg         1.000000 -0.083389  0.084867  0.114133  0.133946   \n",
       "thalach        -0.083389  1.000000 -0.378103 -0.343085 -0.385601   \n",
       "exang           0.084867 -0.378103  1.000000  0.288223  0.257748   \n",
       "oldpeak         0.114133 -0.343085  0.288223  1.000000  0.577537   \n",
       "slop            0.133946 -0.385601  0.257748  0.577537  1.000000   \n",
       "pred_attribute  0.183696 -0.415040  0.397057  0.504092  0.377957   \n",
       "\n",
       "                pred_attribute  \n",
       "age                   0.222853  \n",
       "sex                   0.224469  \n",
       "cp                    0.407075  \n",
       "trestbps              0.157754  \n",
       "chol                  0.070909  \n",
       "fbs                   0.059186  \n",
       "restecg               0.183696  \n",
       "thalach              -0.415040  \n",
       "exang                 0.397057  \n",
       "oldpeak               0.504092  \n",
       "slop                  0.377957  \n",
       "pred_attribute        1.000000  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e1b70405-cc10-4b24-a5a5-38ac9c7ebf0f",
    "_uuid": "16e3dd8adbaaa08120e1ab1e32dd4204e843c60a"
   },
   "source": [
    "### 2. Define training and test samples. \n",
    "\n",
    "The Cleveland data set available from the UCI repository has 303 samples; the training and test data sets were randomly selected with 30% of the original data set corresponding to the test data set.  The relative proportions of the classes of interest (disease/no disease) in both sets were checked to be similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "_cell_guid": "b689622a-a475-40a8-bd33-e2b5e018d528",
    "_uuid": "2e13a97aaee5c269ff8f21fd7b66135927b66156",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Extract features and labels from dataset for local testing:\n",
    "\n",
    "dataset1.dropna(inplace=True, axis=0, how=\"any\")\n",
    "X=dataset1.loc[:, \"age\":\"thal\" ]\n",
    "Y=dataset1[\"pred_attribute\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "_cell_guid": "2dacb7c2-6d4e-4a17-b5cb-d6ecd821c923",
    "_uuid": "c3355ae680b60b0daa713153f05b3709193af7f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model by splitting into train and test sets\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "len(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.797979797979798\n"
     ]
    }
   ],
   "source": [
    "# Check\n",
    "print(len(features_train)/(len(features_train)+ len(features_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "_cell_guid": "5065d9ba-be53-4431-bb86-152ee1673550",
    "_uuid": "00229a787842594dee105c79de5871548613a045"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0.0: 130, 1.0: 42, 3.0: 29, 2.0: 28, 4.0: 8})\n",
      "Counter({0.0: 30, 1.0: 12, 2.0: 7, 3.0: 6, 4.0: 5})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "list1 = []\n",
    "for i in labels_train:\n",
    "    list1.append(i)\n",
    "counter=collections.Counter(list1)\n",
    "print(counter)\n",
    "\n",
    "list2 = []\n",
    "for i in labels_test:\n",
    "    list2.append(i)\n",
    "counter=collections.Counter(list2)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have an relatively small dataset. Therefore, we should do our feature selection based on a cross-\n",
    "validated set. We will check this assumption by comparing the scores on a cross-validated set vs the simple split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slop</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>54.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>53.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>53.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>62.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>342.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>61.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>69.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>53.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex   cp  trestbps   chol  fbs restecg  thalach exang  oldpeak  \\\n",
       "45   58.0  1.0  3.0     112.0  230.0  0.0     2.0    165.0   0.0      2.5   \n",
       "104  49.0  1.0  3.0     120.0  188.0  0.0     0.0    139.0   0.0      2.0   \n",
       "239  42.0  1.0  2.0     120.0  295.0  0.0     0.0    162.0   0.0      0.0   \n",
       "162  54.0  0.0  3.0     110.0  214.0  0.0     0.0    158.0   0.0      1.6   \n",
       "102  57.0  0.0  4.0     128.0  303.0  0.0     2.0    159.0   0.0      0.0   \n",
       "55   54.0  1.0  4.0     124.0  266.0  0.0     2.0    109.0   1.0      2.2   \n",
       "285  58.0  1.0  4.0     114.0  318.0  0.0     1.0    140.0   0.0      4.4   \n",
       "282  55.0  0.0  4.0     128.0  205.0  0.0     1.0    130.0   1.0      2.0   \n",
       "26   58.0  0.0  3.0     120.0  340.0  0.0     0.0    172.0   0.0      0.0   \n",
       "66   60.0  1.0  3.0     140.0  185.0  0.0     2.0    155.0   0.0      3.0   \n",
       "223  53.0  1.0  4.0     123.0  282.0  0.0     0.0     95.0   1.0      2.0   \n",
       "230  52.0  0.0  3.0     136.0  196.0  0.0     2.0    169.0   0.0      0.1   \n",
       "250  57.0  1.0  4.0     110.0  201.0  0.0     0.0    126.0   1.0      1.5   \n",
       "59   51.0  1.0  1.0     125.0  213.0  0.0     2.0    125.0   1.0      1.4   \n",
       "295  41.0  1.0  2.0     120.0  157.0  0.0     0.0    182.0   0.0      0.0   \n",
       "286  58.0  0.0  4.0     170.0  225.0  1.0     2.0    146.0   1.0      2.8   \n",
       "81   53.0  0.0  4.0     130.0  264.0  0.0     2.0    143.0   0.0      0.4   \n",
       "109  39.0  1.0  4.0     118.0  219.0  0.0     0.0    140.0   0.0      1.2   \n",
       "147  41.0  1.0  3.0     112.0  250.0  0.0     0.0    179.0   0.0      0.0   \n",
       "220  41.0  0.0  3.0     112.0  268.0  0.0     2.0    172.0   1.0      0.0   \n",
       "20   64.0  1.0  1.0     110.0  211.0  0.0     2.0    144.0   1.0      1.8   \n",
       "46   51.0  1.0  3.0     110.0  175.0  0.0     0.0    123.0   0.0      0.6   \n",
       "154  64.0  1.0  4.0     120.0  246.0  0.0     2.0     96.0   1.0      2.2   \n",
       "226  47.0  1.0  4.0     112.0  204.0  0.0     0.0    143.0   0.0      0.1   \n",
       "232  49.0  1.0  3.0     118.0  149.0  0.0     2.0    126.0   0.0      0.8   \n",
       "27   66.0  0.0  1.0     150.0  226.0  0.0     0.0    114.0   0.0      2.6   \n",
       "221  54.0  0.0  3.0     108.0  267.0  0.0     2.0    167.0   0.0      0.0   \n",
       "259  57.0  1.0  2.0     124.0  261.0  0.0     0.0    141.0   0.0      0.3   \n",
       "37   57.0  1.0  4.0     150.0  276.0  0.0     2.0    112.0   1.0      0.6   \n",
       "93   44.0  0.0  3.0     108.0  141.0  0.0     0.0    175.0   0.0      0.6   \n",
       "..    ...  ...  ...       ...    ...  ...     ...      ...   ...      ...   \n",
       "272  46.0  1.0  4.0     140.0  311.0  0.0     0.0    120.0   1.0      1.8   \n",
       "148  45.0  1.0  2.0     128.0  308.0  0.0     2.0    170.0   0.0      0.0   \n",
       "277  39.0  0.0  3.0     138.0  220.0  0.0     0.0    152.0   0.0      0.0   \n",
       "179  53.0  1.0  3.0     130.0  246.0  1.0     2.0    173.0   0.0      0.0   \n",
       "100  45.0  1.0  4.0     115.0  260.0  0.0     2.0    185.0   0.0      0.0   \n",
       "200  50.0  0.0  4.0     110.0  254.0  0.0     2.0    159.0   0.0      0.0   \n",
       "246  58.0  1.0  4.0     100.0  234.0  0.0     0.0    156.0   0.0      0.1   \n",
       "116  58.0  1.0  3.0     140.0  211.0  1.0     2.0    165.0   0.0      0.0   \n",
       "269  42.0  1.0  3.0     130.0  180.0  0.0     0.0    150.0   0.0      0.0   \n",
       "72   62.0  1.0  4.0     120.0  267.0  0.0     0.0     99.0   1.0      1.8   \n",
       "25   50.0  0.0  3.0     120.0  219.0  0.0     0.0    158.0   0.0      1.6   \n",
       "167  54.0  0.0  2.0     132.0  288.0  1.0     2.0    159.0   1.0      0.0   \n",
       "289  56.0  1.0  2.0     120.0  240.0  0.0     0.0    169.0   0.0      0.0   \n",
       "176  52.0  1.0  4.0     108.0  233.0  1.0     0.0    147.0   0.0      0.1   \n",
       "291  55.0  0.0  2.0     132.0  342.0  0.0     0.0    166.0   0.0      1.2   \n",
       "39   61.0  1.0  3.0     150.0  243.0  1.0     0.0    137.0   1.0      1.0   \n",
       "196  69.0  1.0  1.0     160.0  234.0  1.0     2.0    131.0   0.0      0.1   \n",
       "89   51.0  0.0  3.0     130.0  256.0  0.0     2.0    149.0   0.0      0.5   \n",
       "70   65.0  0.0  3.0     155.0  269.0  0.0     0.0    148.0   0.0      0.8   \n",
       "88   53.0  0.0  4.0     138.0  234.0  0.0     2.0    160.0   0.0      0.0   \n",
       "245  67.0  1.0  4.0     120.0  237.0  0.0     0.0     71.0   0.0      1.0   \n",
       "281  47.0  1.0  3.0     130.0  253.0  0.0     0.0    179.0   0.0      0.0   \n",
       "214  52.0  1.0  4.0     112.0  230.0  0.0     0.0    160.0   0.0      0.0   \n",
       "9    53.0  1.0  4.0     140.0  203.0  1.0     2.0    155.0   1.0      3.1   \n",
       "198  50.0  0.0  2.0     120.0  244.0  0.0     0.0    162.0   0.0      1.1   \n",
       "254  43.0  1.0  4.0     115.0  303.0  0.0     0.0    181.0   0.0      1.2   \n",
       "195  67.0  1.0  4.0     100.0  299.0  0.0     2.0    125.0   1.0      0.9   \n",
       "118  63.0  1.0  4.0     130.0  330.0  1.0     2.0    132.0   1.0      1.8   \n",
       "47   50.0  1.0  4.0     150.0  243.0  0.0     2.0    128.0   0.0      2.6   \n",
       "174  64.0  1.0  4.0     145.0  212.0  0.0     2.0    132.0   0.0      2.0   \n",
       "\n",
       "    slop   ca thal  \n",
       "45   2.0  1.0  7.0  \n",
       "104  2.0  3.0  7.0  \n",
       "239  1.0  0.0  3.0  \n",
       "162  2.0  0.0  3.0  \n",
       "102  1.0  1.0  3.0  \n",
       "55   2.0  1.0  7.0  \n",
       "285  3.0  3.0  6.0  \n",
       "282  2.0  1.0  7.0  \n",
       "26   1.0  0.0  3.0  \n",
       "66   2.0  0.0  3.0  \n",
       "223  2.0  2.0  7.0  \n",
       "230  2.0  0.0  3.0  \n",
       "250  2.0  0.0  6.0  \n",
       "59   1.0  1.0  3.0  \n",
       "295  1.0  0.0  3.0  \n",
       "286  2.0  2.0  6.0  \n",
       "81   2.0  0.0  3.0  \n",
       "109  2.0  0.0  7.0  \n",
       "147  1.0  0.0  3.0  \n",
       "220  1.0  0.0  3.0  \n",
       "20   2.0  0.0  3.0  \n",
       "46   1.0  0.0  3.0  \n",
       "154  3.0  1.0  3.0  \n",
       "226  1.0  0.0  3.0  \n",
       "232  1.0  3.0  3.0  \n",
       "27   3.0  0.0  3.0  \n",
       "221  1.0  0.0  3.0  \n",
       "259  1.0  0.0  7.0  \n",
       "37   2.0  1.0  6.0  \n",
       "93   2.0  0.0  3.0  \n",
       "..   ...  ...  ...  \n",
       "272  2.0  2.0  7.0  \n",
       "148  1.0  0.0  3.0  \n",
       "277  2.0  0.0  3.0  \n",
       "179  1.0  3.0  3.0  \n",
       "100  1.0  0.0  3.0  \n",
       "200  1.0  0.0  3.0  \n",
       "246  1.0  1.0  7.0  \n",
       "116  1.0  0.0  3.0  \n",
       "269  1.0  0.0  3.0  \n",
       "72   2.0  2.0  7.0  \n",
       "25   2.0  0.0  3.0  \n",
       "167  1.0  1.0  3.0  \n",
       "289  3.0  0.0  3.0  \n",
       "176  1.0  3.0  7.0  \n",
       "291  1.0  0.0  3.0  \n",
       "39   2.0  0.0  3.0  \n",
       "196  2.0  1.0  3.0  \n",
       "89   1.0  0.0  3.0  \n",
       "70   1.0  0.0  3.0  \n",
       "88   1.0  0.0  3.0  \n",
       "245  2.0  0.0  3.0  \n",
       "281  1.0  0.0  3.0  \n",
       "214  1.0  1.0  3.0  \n",
       "9    3.0  0.0  7.0  \n",
       "198  1.0  0.0  3.0  \n",
       "254  2.0  0.0  3.0  \n",
       "195  2.0  2.0  3.0  \n",
       "118  1.0  3.0  7.0  \n",
       "47   2.0  0.0  7.0  \n",
       "174  2.0  2.0  6.0  \n",
       "\n",
       "[252 rows x 13 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train_cross, features_test_cross, labels_train_cross, labels_test_cross = train_test_split(X, Y, test_size=0.15, random_state=0)\n",
    "\n",
    "features_train_cross"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE for SVM - Balancing only on the training set, not the validation set  [This is for the traditional training -not the cross validated one]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:75: DeprecationWarning: Function _ratio_float is deprecated; Use a float for 'ratio' is deprecated from version 0.2. The support will be removed in 0.4. Use a dict, str, or a callable instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "382"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#further divide the 'traditional' non-cross set into training 80/20  for pure training and cross validation  \n",
    "features_train_notoversampled, features_validate, labels_train_notoversampled, labels_validate = train_test_split(features_train, labels_train, test_size = .1, random_state=0)\n",
    "\n",
    "# evaluate the model by splitting into train and test sets\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "len(labels_test)\n",
    "\n",
    "sm = SMOTE(random_state=0, ratio = 1.0, kind= 'svm' )\n",
    "features_train_oversampled, labels_train_oversampled = sm.fit_sample(features_train_notoversampled, labels_train_notoversampled)\n",
    "\n",
    "#re-enter into original variables\n",
    "features_train = features_train_oversampled\n",
    "\n",
    "labels_train = labels_train_oversampled\n",
    "\n",
    "len(labels_train_notoversampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Make models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 make pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing.data import QuantileTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM needs a scalar: https://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf\n",
    "\n",
    "MinMaxScaler rescales the data set such that all feature values are in the range [0, 1]. However, this scaling compress all inliers in the narrow ranges. Minmaxscalar also suffers from the presence of large outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the previous scaler, the centering and scaling statistics of Robust scaler are based on percentiles and are therefore not influenced by a few number of very large marginal outliers. Consequently, the resulting range of the transformed feature values is larger than for the previous scalers and, more importantly, are approximately similar: for both features most of the transformed values lie in a [-2, 3] range as seen in the zoomed-in figure. Note that the outliers themselves are still present in the transformed data. If a separate outlier clipping is desirable, a non-linear transformation is required (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Robust_scaler = preprocessing.RobustScaler(quantile_range=(25, 75))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QuantileTransformer applies a non-linear transformation such that the probability density function of each feature will be mapped to a uniform distribution. In this case, all the data will be mapped in the range [0, 1], even the outliers which cannot be distinguished anymore from the inliers. QuantileTransformer has an additional output_distribution parameter allowing to match a Gaussian distribution instead of a uniform distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Quantile_scalar = preprocessing.QuantileTransformer(output_distribution='normal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selecting features\n",
    "\n",
    "SelectKBest is way to select the most powerfull features. It is also possible to do this manually, in my experience this may improve the results drastically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "skb = SelectKBest(k = 2)\n",
    "skb3 = SelectKBest(k = 3)\n",
    "skb4 = SelectKBest(k = 4)\n",
    "skb7 = SelectKBest(k = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 selecting a Kernel & it's parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### start with RGB, because we don't have a lot of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Nice visualisations:\n",
    "    \n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html \n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# import data\n",
    "X = np.array(features_test)\n",
    "y = np.array(labels_test)\n",
    "class_names = np.array(['No disease', 'Disease 1', 'Disease 2', 'Disease 3', 'Disease 4'],\n",
    "      dtype='<U10')\n",
    "\n",
    "# # Split the data into a training set and a test set\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# # Run classifier, using a model that is too regularized (C too low) to see\n",
    "# # the impact on the results\n",
    "# classifier = svm.SVC(kernel='linear', C=0.01)\n",
    "# y_pred = classifier.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "#     plt.ylabel('True label')\n",
    "#     plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import grid_search\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "\n",
    "def checkmetrics(pred, labels_test, name):\n",
    "    print('The accuracy is of a', name, 'is: ', accuracy_score(pred, labels_test))\n",
    "    # print 'if everyone had 0 score: ', float(float(len(pred))-float(numberpoi))/float(len(pred))\n",
    "    matrix = confusion_matrix(labels_test, pred)\n",
    "    print('There are', matrix[0][0], 'healthy people correctly identified vs', matrix[2][2] +matrix[3][3] +matrix[4][4] +matrix[1][1], 'sick ones. See:\\n', matrix)\n",
    "    print(classification_report(pred, labels_test))\n",
    "#     print('precision score:', precision_score( pred, labels_test))\n",
    "#     if precision_score(pred, labels_test) < recall_score(pred, labels_test):\n",
    "#         print('precision < recall, so higher chance on POIs get identified, but also more false positives')\n",
    "#     if precision_score(pred, labels_test) > recall_score(pred, labels_test):\n",
    "#         print('precision > recall, so lower chance on POIs get identified, but also less false positives')\n",
    "#     print('f1 score: ', f1_score(pred, labels_test), '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is of a support vector machine, Radial Basis Function is:  0.5\n",
      "There are 30 healthy people correctly identified vs 0 sick ones. See:\n",
      " [[30  0  0  0  0]\n",
      " [12  0  0  0  0]\n",
      " [ 7  0  0  0  0]\n",
      " [ 6  0  0  0  0]\n",
      " [ 5  0  0  0  0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.50      0.67        60\n",
      "        1.0       0.00      0.00      0.00         0\n",
      "        2.0       0.00      0.00      0.00         0\n",
      "        3.0       0.00      0.00      0.00         0\n",
      "        4.0       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       1.00      0.50      0.67        60\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "[[30  0  0  0  0]\n",
      " [12  0  0  0  0]\n",
      " [ 7  0  0  0  0]\n",
      " [ 6  0  0  0  0]\n",
      " [ 5  0  0  0  0]]\n",
      "Normalized confusion matrix\n",
      "[[ 1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAECCAYAAADw0Rw8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d006654e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUMAAAEYCAYAAADGepQzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncQD4fw/oF5ioGJoQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d0081dbd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUYAAAEYCAYAAAAgU193AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPm/65QN8md4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d0083946a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = SVC(kernel=\"rbf\")\n",
    "clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "checkmetrics(pred, labels_test, 'support vector machine, Radial Basis Function')\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(labels_test, pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try different scaling methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is of a support vector machine, Radial Basis Function scaled is:  0.55\n",
      "There are 28 healthy people correctly identified vs 5 sick ones. See:\n",
      " [[28  0  1  0  1]\n",
      " [ 6  2  1  2  1]\n",
      " [ 1  0  2  2  2]\n",
      " [ 0  0  5  0  1]\n",
      " [ 0  1  1  2  1]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      0.80      0.86        35\n",
      "        1.0       0.17      0.67      0.27         3\n",
      "        2.0       0.29      0.20      0.24        10\n",
      "        3.0       0.00      0.00      0.00         6\n",
      "        4.0       0.20      0.17      0.18         6\n",
      "\n",
      "avg / total       0.62      0.55      0.57        60\n",
      "\n",
      "The accuracy is of a support vector machine, Radial Basis Function Robust scaled is:  0.483333333333\n",
      "There are 25 healthy people correctly identified vs 4 sick ones. See:\n",
      " [[25  5  0  0  0]\n",
      " [ 6  2  1  2  1]\n",
      " [ 1  0  2  4  0]\n",
      " [ 0  1  5  0  0]\n",
      " [ 1  1  0  3  0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.83      0.76      0.79        33\n",
      "        1.0       0.17      0.22      0.19         9\n",
      "        2.0       0.29      0.25      0.27         8\n",
      "        3.0       0.00      0.00      0.00         9\n",
      "        4.0       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.52      0.48      0.50        60\n",
      "\n",
      "The accuracy is of a support vector machine, Radial Basis Function Normal scaled is:  0.5\n",
      "There are 29 healthy people correctly identified vs 1 sick ones. See:\n",
      " [[29  0  1  0  0]\n",
      " [10  0  2  0  0]\n",
      " [ 6  0  1  0  0]\n",
      " [ 4  1  1  0  0]\n",
      " [ 4  0  0  1  0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      0.55      0.70        53\n",
      "        1.0       0.00      0.00      0.00         1\n",
      "        2.0       0.14      0.20      0.17         5\n",
      "        3.0       0.00      0.00      0.00         1\n",
      "        4.0       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.87      0.50      0.63        60\n",
      "\n",
      "The accuracy is of a support vector machine, Radial Basis Function scaled & selected is:  0.516666666667\n",
      "There are 26 healthy people correctly identified vs 5 sick ones. See:\n",
      " [[26  3  1  0  0]\n",
      " [ 6  1  5  0  0]\n",
      " [ 1  0  3  1  2]\n",
      " [ 0  1  3  0  2]\n",
      " [ 1  1  1  1  1]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.87      0.76      0.81        34\n",
      "        1.0       0.08      0.17      0.11         6\n",
      "        2.0       0.43      0.23      0.30        13\n",
      "        3.0       0.00      0.00      0.00         2\n",
      "        4.0       0.20      0.20      0.20         5\n",
      "\n",
      "avg / total       0.61      0.52      0.55        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "clf =  Pipeline(steps=[('scaling', scaler), ('support vector machine', SVC(kernel=\"rbf\"))])\n",
    "clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "checkmetrics(pred, labels_test, 'support vector machine, Radial Basis Function scaled')\n",
    "\n",
    "clf =  Pipeline(steps=[('scaling',Robust_scaler), ('support vector machine', SVC(kernel=\"rbf\"))])\n",
    "clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "checkmetrics(pred, labels_test, 'support vector machine, Radial Basis Function Robust scaled')\n",
    "\n",
    "clf =  Pipeline(steps=[('scaling', Quantile_scalar), ('support vector machine', SVC(kernel=\"rbf\"))])\n",
    "clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "checkmetrics(pred, labels_test, 'support vector machine, Radial Basis Function Normal scaled')\n",
    "\n",
    "clf =  Pipeline(steps=[('scaling',scaler),(\"SKB\", skb), ('support vector machine', SVC(kernel=\"rbf\"))])\n",
    "clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "checkmetrics(pred, labels_test, 'support vector machine, Radial Basis Function scaled & selected')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is of a support vector machine, Poly, scaled & clustered is:  0.566666666667\n",
      "There are 29 healthy people correctly identified vs 5 sick ones. See:\n",
      " [[29  1  0  0  0]\n",
      " [ 6  5  1  0  0]\n",
      " [ 3  2  0  0  2]\n",
      " [ 0  4  0  0  2]\n",
      " [ 2  2  1  0  0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      0.72      0.83        40\n",
      "        1.0       0.42      0.36      0.38        14\n",
      "        2.0       0.00      0.00      0.00         2\n",
      "        3.0       0.00      0.00      0.00         0\n",
      "        4.0       0.00      0.00      0.00         4\n",
      "\n",
      "avg / total       0.74      0.57      0.64        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# trying poly\n",
    "clf =  Pipeline(steps=[('scaling',scaler),(\"SKB\", skb), ('support vector machine', SVC(kernel=\"poly\"))])\n",
    "clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "checkmetrics(pred, labels_test, 'support vector machine, Poly, scaled & clustered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to lay far too much weight on the first category due to their high number. \n",
    "\n",
    "##### Try other peoples classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#used some ideas from http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "\n",
    "#linear kernel\n",
    "def svm_linear(features_train, features_test, labels_train, labels_test):\n",
    "\n",
    "    clf = svm.SVC(\n",
    "        C=1.0, \n",
    "        kernel='linear', \n",
    "        probability=False, \n",
    "        shrinking=True, \n",
    "        tol=1e-3, \n",
    "        verbose=False, \n",
    "        max_iter=-1, \n",
    "        decision_function_shape=None,\n",
    "        random_state=None)\n",
    "\n",
    "    clf.fit(features_train, labels_train)\n",
    "    pred = clf.predict(features_test)\n",
    "    print(\"Kernel: Linear\")\n",
    "    print(\"Performance: \"  + str(clf.score(features_test, labels_test)))\n",
    "    print(\"\")\n",
    "    return pred\n",
    "\n",
    "#polynomial kernel from degrees 2 to 5\n",
    "def svm_poly(features_train, features_test, labels_train, labels_test):\n",
    "\n",
    "    for d in [2, 3, 4, 5]:\t\n",
    "\n",
    "        clf = svm.SVC(\n",
    "            C=1.0,\n",
    "            kernel='poly', \n",
    "            degree=d,\n",
    "            gamma='auto',\n",
    "            coef0=0.0,\n",
    "            probability=False,\n",
    "            shrinking=True,\n",
    "            tol=1e-3,\n",
    "            verbose=False,\n",
    "            max_iter=400000,\n",
    "            decision_function_shape=None,\n",
    "            random_state=None)\n",
    "        clf.fit(features_train, labels_train)\n",
    "        pred = clf.predict(features_test)\n",
    "        print(\"Kernel: Polynomial\")\n",
    "        print(\"Degree: \" + str(d))\n",
    "        print(\"Performance: \"  + str(clf.score(features_test, labels_test)))\n",
    "        print(\"\")\n",
    "    return pred\n",
    "\n",
    "#radial basis function kernel\n",
    "def svm_rbf(features_train, features_test, labels_train, labels_test):\n",
    "\n",
    "    clf = svm.SVC(\n",
    "        C=1.0,\n",
    "        kernel='rbf',\n",
    "        gamma='auto',\n",
    "        probability=False,\n",
    "        shrinking=True,\n",
    "        tol=1e-3,\n",
    "        verbose=False,\n",
    "        max_iter=-1,\n",
    "        decision_function_shape=None,\n",
    "        random_state=None)\n",
    "\n",
    "    clf.fit(features_train, labels_train)\n",
    "    pred = clf.predict(features_test)\n",
    "    print(\"Kernel: Radial Basis Function\")\n",
    "    print(\"Performance: \"  + str(clf.score(features_test, labels_test)))\n",
    "    print(\"\")\n",
    "    return pred\n",
    "\n",
    "#sigmoid function kernel\n",
    "def svm_sigmoid(features_train, features_test, labels_train, labels_test):\n",
    "\n",
    "    clf = svm.SVC(\n",
    "        C=1.0,\n",
    "        kernel='sigmoid',\n",
    "        gamma='auto',\n",
    "        coef0=0.0,\n",
    "        probability=False,\n",
    "        shrinking=True,\n",
    "        tol=1e-3,\n",
    "        verbose=False,\n",
    "        max_iter=-1,\n",
    "        decision_function_shape=None,\n",
    "        random_state=None)\n",
    "    clf.fit(features_train, labels_train)\n",
    "    pred = clf.predict(features_test)\n",
    "    print(\"Kernel: Sigmoid\")\n",
    "    print(\"Performance: \"  + str(clf.score(features_test, labels_test)))\n",
    "    print(\"\")\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "_cell_guid": "4a94b089-0ab5-495b-a2ed-434001cf61af",
    "_uuid": "92ce1308415ee9775a6f29d19d5eeb4b2c6d959a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: Linear\n",
      "Performance: 0.566666666667\n",
      "\n",
      "The accuracy is of a linearSVM, from function is:  0.566666666667\n",
      "There are 28 healthy people correctly identified vs 6 sick ones. See:\n",
      " [[28  2  0  0  0]\n",
      " [ 6  2  1  2  1]\n",
      " [ 1  1  2  3  0]\n",
      " [ 0  0  4  2  0]\n",
      " [ 2  0  1  2  0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      0.76      0.84        37\n",
      "        1.0       0.17      0.40      0.24         5\n",
      "        2.0       0.29      0.25      0.27         8\n",
      "        3.0       0.33      0.22      0.27         9\n",
      "        4.0       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.68      0.57      0.61        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:218: ConvergenceWarning: Solver terminated early (max_iter=400000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: Polynomial\n",
      "Degree: 2\n",
      "Performance: 0.366666666667\n",
      "\n",
      "Kernel: Polynomial\n",
      "Degree: 3\n",
      "Performance: 0.416666666667\n",
      "\n",
      "Kernel: Polynomial\n",
      "Degree: 4\n",
      "Performance: 0.416666666667\n",
      "\n",
      "Kernel: Polynomial\n",
      "Degree: 5\n",
      "Performance: 0.5\n",
      "\n",
      "The accuracy is of a polySVM, from function is:  0.5\n",
      "There are 21 healthy people correctly identified vs 9 sick ones. See:\n",
      " [[21  6  2  1  0]\n",
      " [ 4  4  1  2  1]\n",
      " [ 3  1  3  0  0]\n",
      " [ 0  3  0  2  1]\n",
      " [ 2  2  0  1  0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.70      0.70      0.70        30\n",
      "        1.0       0.33      0.25      0.29        16\n",
      "        2.0       0.43      0.50      0.46         6\n",
      "        3.0       0.33      0.33      0.33         6\n",
      "        4.0       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.52      0.50      0.51        60\n",
      "\n",
      "Kernel: Radial Basis Function\n",
      "Performance: 0.5\n",
      "\n",
      "The accuracy is of a RBFSVM, from function is:  0.5\n",
      "There are 30 healthy people correctly identified vs 0 sick ones. See:\n",
      " [[30  0  0  0  0]\n",
      " [12  0  0  0  0]\n",
      " [ 7  0  0  0  0]\n",
      " [ 6  0  0  0  0]\n",
      " [ 5  0  0  0  0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.50      0.67        60\n",
      "        1.0       0.00      0.00      0.00         0\n",
      "        2.0       0.00      0.00      0.00         0\n",
      "        3.0       0.00      0.00      0.00         0\n",
      "        4.0       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       1.00      0.50      0.67        60\n",
      "\n",
      "Kernel: Sigmoid\n",
      "Performance: 0.5\n",
      "\n",
      "The accuracy is of a SIGSVM, from function is:  0.5\n",
      "There are 30 healthy people correctly identified vs 0 sick ones. See:\n",
      " [[30  0  0  0  0]\n",
      " [12  0  0  0  0]\n",
      " [ 7  0  0  0  0]\n",
      " [ 6  0  0  0  0]\n",
      " [ 5  0  0  0  0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.50      0.67        60\n",
      "        1.0       0.00      0.00      0.00         0\n",
      "        2.0       0.00      0.00      0.00         0\n",
      "        3.0       0.00      0.00      0.00         0\n",
      "        4.0       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       1.00      0.50      0.67        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Run SVM with a linear kernel\n",
    "pred = svm_linear(features_train, features_test, labels_train, labels_test)\n",
    "checkmetrics(pred, labels_test, 'linearSVM, from function')\n",
    "\n",
    "#Run SVM with a polynomial kernel\n",
    "pred = svm_poly(features_train, features_test, labels_train, labels_test)\n",
    "checkmetrics(pred, labels_test, 'polySVM, from function')\n",
    "\n",
    "#Run SVM with a radial basis function kernel\n",
    "pred = svm_rbf(features_train, features_test, labels_train, labels_test)\n",
    "checkmetrics(pred, labels_test, 'RBFSVM, from function')\n",
    "\n",
    "#Run SVM with a sigmoid kernel\n",
    "pred = svm_sigmoid(features_train, features_test, labels_train, labels_test)\n",
    "checkmetrics(pred, labels_test, 'SIGSVM, from function')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the Linear one is performing a little bit better here, there seems to be a very big focus on the non-disease. Still not good: try some automatic tuning: trying gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is of a support vector machine, with gridsearch is:  0.533333333333\n",
      "There are 28 healthy people correctly identified vs 4 sick ones. See:\n",
      " [[28  2  0  0  0]\n",
      " [ 6  2  1  3  0]\n",
      " [ 1  0  2  2  2]\n",
      " [ 0  1  5  0  0]\n",
      " [ 1  1  1  2  0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      0.78      0.85        36\n",
      "        1.0       0.17      0.33      0.22         6\n",
      "        2.0       0.29      0.22      0.25         9\n",
      "        3.0       0.00      0.00      0.00         7\n",
      "        4.0       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.62      0.53      0.57        60\n",
      "\n",
      "The accuracy is of a support vector machine, with gridsearch & only the best 2 features is:  0.483333333333\n",
      "There are 26 healthy people correctly identified vs 3 sick ones. See:\n",
      " [[26  3  0  0  1]\n",
      " [ 6  1  1  0  4]\n",
      " [ 2  0  1  0  4]\n",
      " [ 0  1  0  0  5]\n",
      " [ 2  1  0  1  1]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.87      0.72      0.79        36\n",
      "        1.0       0.08      0.17      0.11         6\n",
      "        2.0       0.14      0.50      0.22         2\n",
      "        3.0       0.00      0.00      0.00         1\n",
      "        4.0       0.20      0.07      0.10        15\n",
      "\n",
      "avg / total       0.58      0.48      0.52        60\n",
      "\n",
      "The accuracy is of a support vector machine, with gridsearch & only the best 7 features is:  0.5\n",
      "There are 27 healthy people correctly identified vs 3 sick ones. See:\n",
      " [[27  1  1  0  1]\n",
      " [ 6  1  1  2  2]\n",
      " [ 1  1  2  2  1]\n",
      " [ 1  0  5  0  0]\n",
      " [ 1  0  1  3  0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.90      0.75      0.82        36\n",
      "        1.0       0.08      0.33      0.13         3\n",
      "        2.0       0.29      0.20      0.24        10\n",
      "        3.0       0.00      0.00      0.00         7\n",
      "        4.0       0.00      0.00      0.00         4\n",
      "\n",
      "avg / total       0.59      0.50      0.54        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Can we use gridsearch for feature selection?\n",
    "\n",
    "# still not good: try some automatic tuning:\n",
    "# trying gridsearch\n",
    "parameters = {'kernel':('poly', 'rbf'), 'C':[1, 10]}\n",
    "svr = svm.SVC()\n",
    "grid = grid_search.GridSearchCV(svr, parameters)\n",
    "clf =  Pipeline(steps=[('scaling',scaler), (\"Grid\", grid)])\n",
    "clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "checkmetrics(pred, labels_test, 'support vector machine, with gridsearch')\n",
    "\n",
    "parameters = {'kernel':('poly', 'rbf'), 'C':[1, 10]}\n",
    "svr = svm.SVC()\n",
    "grid = grid_search.GridSearchCV(svr, parameters)\n",
    "clf =  Pipeline(steps=[('scaling',scaler),(\"SKB\", skb), (\"Grid\", grid)])\n",
    "clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "checkmetrics(pred, labels_test, 'support vector machine, with gridsearch & only the best 2 features')\n",
    "\n",
    "parameters = {'kernel':('poly', 'rbf'), 'C':[1, 10]}\n",
    "svr = svm.SVC()\n",
    "grid = grid_search.GridSearchCV(svr, parameters)\n",
    "clf =  Pipeline(steps=[('scaling',scaler),(\"SKB\", skb7), (\"Grid\", grid)])\n",
    "clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "checkmetrics(pred, labels_test, 'support vector machine, with gridsearch & only the best 7 features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe we were just unlucky, had a difficult split? We have a relatively small dataset. Therefore, we should do our feature selection based on a cross-validated set. Let's check if the scoring is the same on a cross validated set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.58 (+/- 0.06)\n",
      "Accuracy: 0.58 (+/- 0.07)\n",
      "Accuracy: 0.57 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "# We have an relatively small dataset. Therefore, we should do our feature selection based on a cross-\n",
    "# validated set. Let's check if the scoring is the same on a cross validated set.\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "# split into 5\n",
    "scores = cross_val_score(clf, features_train_cross, labels_train_cross, cv=5)\n",
    "                                            \n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf = svm.SVC(kernel='linear', C=0.2)\n",
    "# split into 5\n",
    "scores = cross_val_score(clf, features_train_cross, labels_train_cross, cv=5)\n",
    "                                            \n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf = svm.SVC(kernel='linear', C=0.1)\n",
    "# split into 5\n",
    "scores = cross_val_score(clf, features_train_cross, labels_train_cross, cv=5)\n",
    "                                            \n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# That accuracy seems a bit higher. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-59-6ab4c62399b8>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-59-6ab4c62399b8>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    for (f in feature.names) {\u001b[0m\n\u001b[1;37m                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "feature.names=names(heart.data)\n",
    "\n",
    "for (f in feature.names) {\n",
    "  if (class(heart.data[[f]])==\"factor\") {\n",
    "    levels <- unique(c(heart.data[[f]]))\n",
    "    heart.data[[f]] <- factor(heart.data[[f]],\n",
    "                   labels=make.names(levels))\n",
    "  }\n",
    "}\n",
    "set.seed(10)\n",
    "inTrainRows <- createDataPartition(heart.data$num,p=0.7,list=FALSE)\n",
    "trainData2 <- heart.data[inTrainRows,]\n",
    "testData2 <-  heart.data[-inTrainRows,]\n",
    "\n",
    "\n",
    "fitControl <- trainControl(method = \"repeatedcv\",\n",
    "                           number = 10,\n",
    "                           repeats = 10,\n",
    "                           ## Estimate class probabilities\n",
    "                           classProbs = TRUE,\n",
    "                           ## Evaluate performance using\n",
    "                           ## the following function\n",
    "                           summaryFunction = twoClassSummary)\n",
    "\n",
    "set.seed(10)\n",
    "gbmModel <- train(num ~ ., data = trainData2,\n",
    "                 method = \"gbm\",\n",
    "                 trControl = fitControl,\n",
    "                 verbose = FALSE,\n",
    "                 tuneGrid = gbmGrid,\n",
    "                 ## Specify which metric to optimize\n",
    "                 metric = \"ROC\")\n",
    "gbmPrediction <- predict(gbmModel, testData2)\n",
    "gbmPredictionprob <- predict(gbmModel, testData2, type='prob')[2]\n",
    "gbmConfMat <- confusionMatrix(gbmPrediction, testData2[,\"num\"])\n",
    "#ROC Curve\n",
    "AUC$gbm <- roc(as.numeric(testData2$num),as.numeric(as.matrix((gbmPredictionprob))))$auc\n",
    "Accuracy$gbm <- gbmConfMat$overall['Accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set.seed(10)\n",
    "svmModel <- train(num ~ ., data = trainData2,\n",
    "                 method = \"svmRadial\",\n",
    "                 trControl = fitControl,\n",
    "                 preProcess = c(\"center\", \"scale\"),\n",
    "                 tuneLength = 8,\n",
    "                 metric = \"ROC\")\n",
    "svmPrediction <- predict(svmModel, testData2)\n",
    "svmPredictionprob <- predict(svmModel, testData2, type='prob')[2]\n",
    "svmConfMat <- confusionMatrix(svmPrediction, testData2[,\"num\"])\n",
    "#ROC Curve\n",
    "AUC$svm <- roc(as.numeric(testData2$num),as.numeric(as.matrix((svmPredictionprob))))$auc\n",
    "Accuracy$svm <- svmConfMat$overall['Accuracy'] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
